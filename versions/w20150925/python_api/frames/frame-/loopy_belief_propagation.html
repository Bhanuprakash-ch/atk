<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8">
    
    <title>Frame loopy_belief_propagation &mdash; Trusted Analytics Platform 0.4.0 documentation</title>
    
    <link rel="stylesheet" type="text/css" href="../../../f_static/css/spc-bootstrap.css">
    <link rel="stylesheet" type="text/css" href="../../../f_static/css/spc-extend.css">
    <link rel="stylesheet" href="../../../f_static/scipy.css" type="text/css" >
    <link rel="stylesheet" href="../../../f_static/pygments.css" type="text/css" >
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     '0.4.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../../f_static/jquery.js"></script>
    <script type="text/javascript" src="../../../f_static/underscore.js"></script>
    <script type="text/javascript" src="../../../f_static/doctools.js"></script>
    <script type="text/javascript" src="../../../f_static/js/copybutton.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" >
    <link rel="top" title="Trusted Analytics Platform 0.4.0 documentation" href="../../../index.html" >
    <link rel="up" title="Frames Frame" href="index.html" >
    <link rel="next" title="Frame name" href="name.html" >
    <link rel="prev" title="Frame loadjdbc" href="loadjdbc.html" > 
  </head>
  <body>

  <div class="container">
    <div class="header">
    </div>
  </div>


    <div class="container">
      <div class="main">
        
	<div class="row-fluid">
	  <div class="span12">
	    <div class="spc-navbar">
              
    <ul class="nav nav-pills pull-left">
	
        <li class="active"><a href="../../../index.html">Trusted Analytics</a></li>
	
          <li class="active"><a href="../../index.html" >Python API</a></li>
          <li class="active"><a href="../index.html" >Frames</a></li>
          <li class="active"><a href="index.html" accesskey="U"><code class="docutils literal"><span class="pre">Frames</span></code> Frame</a></li> 
    </ul>
              
              
    <ul class="nav nav-pills pull-right">
      <li class="active">
        <a href="loadjdbc.html" title="Frame loadjdbc"
           accesskey="P">previous</a>
      </li>
      <li class="active">
        <a href="name.html" title="Frame name"
           accesskey="N">next</a>
      </li>
      <li class="active">
        <a href="../../../genindex.html" title="General Index"
           accesskey="I">index</a>
      </li>
    </ul>
              
	    </div>
	  </div>
	</div>
        

	<div class="row-fluid">
      <div class="spc-rightsidebar span3">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
<h3><a href="../../../index.html">Table Of Contents</a></h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../intro.html">Technical Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ds_over.html">User Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dev_over.html">Extending Trusted Analytics Platform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ad_over.html">Deploy and Run ATK App on DP2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../rest_api/v1/index.html">REST API</a></li>
</ul>
<ul class="simple">
</ul>

        </div>
      </div>
          <div class="span9">
            
        <div class="bodywrapper">
          <div class="body" id="spc-section-body">
            
  <div class="section" id="frame-loopy-belief-propagation">
<span id="python-api-frames-frame-loopy-belief-propagation"></span><h1><a class="reference internal" href="index.html"><em>Frame</em></a>  loopy_belief_propagation<a class="headerlink" href="#frame-loopy-belief-propagation" title="Permalink to this headline">¶</a></h1>
<hr class="docutils" />
<dl class="function">
<dt id="loopy_belief_propagation">
<code class="descname">loopy_belief_propagation</code><span class="sig-paren">(</span><em>self</em>, <em>src_col_name</em>, <em>dest_col_name</em>, <em>weight_col_name</em>, <em>src_label_col_name</em>, <em>result_col_name=None</em>, <em>ignore_vertex_type=None</em>, <em>max_iterations=None</em>, <em>convergence_threshold=None</em>, <em>anchor_threshold=None</em>, <em>smoothing=None</em>, <em>max_product=None</em>, <em>power=None</em><span class="sig-paren">)</span><a class="headerlink" href="#loopy_belief_propagation" title="Permalink to this definition">¶</a></dt>
<dd><p>Message passing to infer state probabilities.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>src_col_name</strong> : unicode</p>
<blockquote>
<div><p>The column name for the
source vertex id.</p>
</div></blockquote>
<p><strong>dest_col_name</strong> : unicode</p>
<blockquote>
<div><p>The column name for the
destination vertex id.</p>
</div></blockquote>
<p><strong>weight_col_name</strong> : unicode</p>
<blockquote>
<div><p>The column name for the
edge weight.</p>
</div></blockquote>
<p><strong>src_label_col_name</strong> : unicode</p>
<blockquote>
<div><p>The column name for the
label properties for the source vertex.</p>
</div></blockquote>
<p><strong>result_col_name</strong> : unicode (default=None)</p>
<blockquote>
<div><p>The column name for the results (holding
the post labels for the vertices).</p>
</div></blockquote>
<p><strong>ignore_vertex_type</strong> : bool (default=None)</p>
<blockquote>
<div><p>If True, all vertex will be treated as training data.
Default is False.</p>
</div></blockquote>
<p><strong>max_iterations</strong> : int32 (default=None)</p>
<blockquote>
<div><p>The maximum number of
supersteps that the algorithm will execute.
The valid value range is all positive int.
The default value is 10.</p>
</div></blockquote>
<p><strong>convergence_threshold</strong> : float32 (default=None)</p>
<blockquote>
<div><p>The amount of change in cost
function that will be tolerated at convergence.
If the change is less than this threshold, the algorithm exits earlier
before it reaches the maximum number of supersteps.
The valid value range is all float and zero.
The default value is 0.00000001f.</p>
</div></blockquote>
<p><strong>anchor_threshold</strong> : float64 (default=None)</p>
<blockquote>
<div><p>The parameter that determines
if a node&#8217;s posterior will be updated or not.
If a node&#8217;s maximum prior value is greater than this threshold, the node will be
treated as anchor node, whose posterior will inherit from prior without update.
This is for the case where we have confident prior estimation for some
nodes and don&#8217;t want the algorithm to update these nodes.
The valid value range is in [0, 1].
Default is 1.0.</p>
</div></blockquote>
<p><strong>smoothing</strong> : float32 (default=None)</p>
<blockquote>
<div><p>The Ising smoothing parameter.
This parameter adjusts the relative strength of closeness encoded edge
weights, similar to the width of Gaussian distribution.
Larger value implies smoother decay and the edge weight becomes less important.
Default is 2.0.</p>
</div></blockquote>
<p><strong>max_product</strong> : bool (default=None)</p>
<blockquote>
<div><p>Should <abbr title="Loopy Belief Propagation">LBP</abbr> use max_product or not.
Default is False.</p>
</div></blockquote>
<p><strong>power</strong> : float32 (default=None)</p>
<blockquote>
<div><p>Power coefficient for power edge potential.
Default is 0.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">: dict</p>
<blockquote class="last">
<div><p>a 2-column frame:</p>
<blockquote>
<div><dl class="docutils">
<dt>vertex: int</dt>
<dd><p class="first last">A vertex id.</p>
</dd>
<dt>result <span class="classifier-delimiter">:</span> <span class="classifier">Vector (long)</span></dt>
<dd><p class="first last">label vector for the results (for the node id in column 1).</p>
</dd>
</dl>
</div></blockquote>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p>Loopy belief propagation on <a class="reference internal" href="../../../glossary.html#term-markov-random-fields"><span class="xref std std-term">Markov Random Fields</span></a> (MRF).
<a class="reference internal" href="../../graphs/graph-/ml/belief_propagation.html#python-api-graphs-graph-ml-belief-propagation"><span>Belief Propagation</span></a>
(BP) was originally designed for acyclic graphical models, then it
was found that the <abbr title="Belief Propagation">BP</abbr> algorithm can be used in general graphs.
The algorithm is then sometimes called &#8220;Loopy&#8221; Belief Propagation (LBP),
because graphs typically contain cycles, or loops.</p>
<p><strong>Loopy Belief Propagation (LBP)</strong></p>
<p>Loopy Belief Propagation (LBP) is a message passing algorithm for inferring
state probabilities, given a graph and a set of noisy initial estimates.
The <abbr title="Loopy Belief Propagation">LBP</abbr> implementation assumes that the joint distribution of the
data is given by a Boltzmann distribution.</p>
<p>For more information about <abbr title="Loopy Belief Propagation">LBP</abbr>, see: &#8220;K. Murphy, Y. Weiss, and M. Jordan,
Loopy-belief Propagation for Approximate Inference: An Empirical Study, UAI 1999.&#8221;</p>
<p><abbr title="Loopy Belief Propagation">LBP</abbr> has a wide range of applications in structured prediction, such as
low-level vision and influence spread in social networks, where we have prior
noisy predictions for a large set of random variables and a graph encoding
relationships between those variables.</p>
<p>The algorithm performs approximate inference on an <a class="reference internal" href="../../../glossary.html#term-undirected-graph"><span class="xref std std-term">undirected graph</span></a> of
hidden variables, where each variable is represented as a node, and each edge
encodes relations to its neighbors.
Initially, a prior noisy estimate of state probabilities is given to each
node, then the algorithm infers the posterior distribution of each node by
propagating and collecting messages to and from its neighbors and updating
the beliefs.</p>
<p>In graphs containing loops, convergence is not guaranteed, though <abbr title="Loopy Belief Propagation">LBP</abbr> has
demonstrated empirical success in many areas and in practice often converges
close to the true joint probability distribution.</p>
<p><strong>Discrete Loopy Belief Propagation</strong></p>
<p><abbr title="Loopy Belief Propagation">LBP</abbr> is typically considered a <a class="reference internal" href="../../../glossary.html#term-semi-supervised-learning"><span class="xref std std-term">semi-supervised machine learning</span></a> algorithm as</p>
<ol class="arabic simple">
<li>there is typically no ground truth observation of states</li>
<li>the algorithm is primarily concerned with estimating a joint
probability function rather than
with <a class="reference internal" href="../../../glossary.html#term-classification"><span class="xref std std-term">classification</span></a> or point prediction.</li>
</ol>
<p>The standard (discrete) <abbr title="Loopy Belief Propagation">LBP</abbr> algorithm requires a set of probability thresholds
to be considered a classifier.
Nonetheless, the discrete <abbr title="Loopy Belief Propagation">LBP</abbr> algorithm allows Test/Train/Validate splits of
the data and the algorithm will treat &#8220;Train&#8221; observations
differently from &#8220;Test&#8221; and &#8220;Validate&#8221; observations.
Vertices labeled with &#8220;Test&#8221; or &#8220;Validate&#8221; will be treated as though they have
uninformative (uniform) priors and are
allowed to receive messages, but not send messages.
This simulates a &#8220;scoring scenario&#8221; in which a new observation is added to a
graph containing fully trained <abbr title="Loopy Belief Propagation">LBP</abbr> posteriors, the new vertex is scored based
on received messages, but the full <abbr title="Loopy Belief Propagation">LBP</abbr> algorithm is not repeated in full.
This behavior can be turned off by setting the <code class="docutils literal"><span class="pre">ignore_vertex_type</span></code> parameter
to True.
When <code class="docutils literal"><span class="pre">ignore_vertex_type=True</span></code>, all nodes will be considered &#8220;Train&#8221;
regardless of their sample type designation.
The Gaussian (continuous) version of <abbr title="Loopy Belief Propagation">LBP</abbr> does not allow Train/Test/Validate
splits.</p>
<p>The standard <abbr title="Loopy Belief Propagation">LBP</abbr> algorithm included with the toolkit assumes an ordinal and
cardinal set of discrete states.
For notational convenience, we&#8217;ll denote the value of state <img class="math" src="../../../f_images/math/2e1911d6c0e2374d2139d10492392e6e75b5a0aa.png" alt="s_{i}"/> as
<img class="math" src="../../../f_images/math/a581f053bbfa5115f42c13094857cdd12a37ec49.png" alt="i"/>, and the prior probability of state
<img class="math" src="../../../f_images/math/2e1911d6c0e2374d2139d10492392e6e75b5a0aa.png" alt="s_{i}"/> as <img class="math" src="../../../f_images/math/09b2ea56ef067824027053ca21794b0d2165026d.png" alt="prior_{i}"/>.</p>
<p>Each node sends out initial messages of the form:</p>
<div class="math">
<p><img src="../../../f_images/math/7afea94052a7255274c2d4ff4adebe5a7209d81d.png" alt="\ln \left ( \sum_{s_{j}} \exp \left ( - \frac { | i - j | ^{p} }{ n - 1 } \
* w * s + \ln (prior_{i}) \right ) \right )"/></p>
</div><p>Where</p>
<ul class="simple">
<li><img class="math" src="../../../f_images/math/8659700e6646cd91bc02c32affaa5ec046ee9935.png" alt="w"/> is the weight between the messages destination and origin vertices</li>
<li><img class="math" src="../../../f_images/math/6859317dd1b439cef34131bcd4bafee8393444e0.png" alt="s"/> is the <a class="reference internal" href="../../../glossary.html#term-smoothing"><span class="xref std std-term">smoothing</span></a> parameter</li>
<li><img class="math" src="../../../f_images/math/3eca8557203e86160952e1c0f735f7417f3285b1.png" alt="p"/> is the power parameter</li>
<li><img class="math" src="../../../f_images/math/413f8a8e40062a9090d9d50b88bc7b551b314c26.png" alt="n"/> is the number of states</li>
</ul>
<p>The larger the weight between two nodes, or the higher the smoothing parameter,
the more neighboring vertices are assumed to &#8220;agree&#8221; on states.
We represent messages as sums of log probabilities rather than products
of non-logged probabilities which makes it easier to subtract messages in the
future steps of the algorithm.
Also note that the states are cardinal in the sense that the &#8220;pull&#8221; of state
<img class="math" src="../../../f_images/math/a581f053bbfa5115f42c13094857cdd12a37ec49.png" alt="i"/> on state <img class="math" src="../../../f_images/math/d32c78b759903e3f4bd4fd2ce0b86358f7500c5d.png" alt="j"/> depends on the distance between <img class="math" src="../../../f_images/math/a581f053bbfa5115f42c13094857cdd12a37ec49.png" alt="i"/> and
<img class="math" src="../../../f_images/math/d32c78b759903e3f4bd4fd2ce0b86358f7500c5d.png" alt="j"/>.
The <em>power</em> parameter intensifies the rate at which the pull of distant states
drops off.</p>
<p>In order for the algorithm to work properly, all edges of the graph must be
bidirectional.
In other words, messages need to be able to flow in both directions across
every edge.
Bidirectional edges can be enforced during graph building, but the <abbr title="Loopy Belief Propagation">LBP</abbr> function
provides an option to do an initial check for bidirectionality using the
<code class="docutils literal"><span class="pre">bidirectional_check=True</span></code> option.
If not all the edges of the graph are bidirectional, the algorithm will return
an error.</p>
<p>Look at a case where a node has two states, 0 and 1.
The 0 state has a prior probability of 0.9 and the 1 state has a prior
probability of 0.2.
The states have uniform weights of 1, power of 1 and a smoothing parameter of 2.
The nodes initial message would be <img class="math" src="../../../f_images/math/3079aadf373db4dad93b9940cc3d3c1e0a50b0a2.png" alt="\textstyle \left [ \ln \left ( 0.2 \
+ 0.8 e ^{-2} \right ), \ln \left ( 0.8 + 0.2 e ^{-2} \right ) \right ]"/>,
which gets sent to each of that node&#8217;s neighbors.
Note that messages will typically not be proper probability distributions,
hence each message is normalized so that the probability of all states sum to 1
before being sent out.
For simplicity of discussion, we will consider all messages as normalized
messages.</p>
<p>After nodes have sent out their initial messages, they then update their
beliefs based on messages that they have received from their neighbors,
denoted by the set <img class="math" src="../../../f_images/math/e9203da50e1059455123460d4e716c9c7f440cc3.png" alt="k"/>.</p>
<p>Updated Posterior Beliefs:</p>
<div class="math">
<p><img src="../../../f_images/math/2698aa55e8a9d5cc8a66eb4844aaefa35e7abb2d.png" alt="\ln (newbelief) = \propto \exp \left [ \ln (prior) + \sum_k message _{k} \
\right ]"/></p>
</div><p>Note that the messages in the above equation are still in log form.
Nodes then send out new messages which take the same form as their initial
messages, with updated beliefs in place of priors and subtracting out the
information previously received from the new message&#8217;s recipient.
The recipient&#8217;s prior message is subtracted out to prevent feedback loops of
nodes &#8220;learning&#8221; from themselves.</p>
<div class="math">
<p><img src="../../../f_images/math/f87351af351b109819c482b5bfd285734954d0bd.png" alt="\ln \left ( \sum_{s_{j}} \exp \left ( - \frac { | i - j | ^{p} }{ n - 1 } \
* w * s + \ln (newbelief_{i}) - \
previous\ message\ from\ recipient \right ) \right )"/></p>
</div><p>In updating beliefs, new beliefs tend to be most influenced by the largest
message.
Setting the <code class="docutils literal"><span class="pre">max_product</span></code> option to &#8220;True&#8221; ignores all incoming messages
other than the strongest signal.
Doing this results in approximate solutions, but requires significantly less
memory and run-time than the more exact computation.
Users should consider this option when processing power is a constraint and
approximate solutions to <abbr title="Loopy Belief Propagation">LBP</abbr> will be sufficient.</p>
<p>This process of updating and message passing continues until the convergence
criteria is met or the maximum number of <a class="reference internal" href="../../../glossary.html#term-supersteps"><span class="xref std std-term">supersteps</span></a> is
reached without converging.
A node is said to converge if the total change in its distribution (the sum of
absolute value changes in state probabilities) is less than
the <code class="docutils literal"><span class="pre">convergence_threshold</span></code> parameter.
Convergence is a local phenomenon; not all nodes will converge at the same
time.
It is also possible for some (most) nodes to converge and others to never
converge.
The algorithm requires all nodes to converge before declaring that the
algorithm has converged overall.
If this condition is not met, the algorithm will continue up to the maximum
number of <a class="reference internal" href="../../../glossary.html#term-supersteps"><span class="xref std std-term">supersteps</span></a>.</p>
<p>See: <a class="reference external" href="http://en.wikipedia.org/wiki/Belief_propagation">http://en.wikipedia.org/wiki/Belief_propagation</a>.</p>
<p class="rubric">Examples</p>
<p>input frame (lbp.csv)
&#8220;a&#8221;        &#8220;b&#8221;        &#8220;c&#8221;        &#8220;d&#8221;
1,         2,         0.5,       &#8220;0.5,0.5&#8221;
2,         3,         0.4,       &#8220;-1,-1&#8221;
3,         1,         0.1,       &#8220;0.8,0.2&#8221;</p>
<p>script</p>
<p>ta.connect()
s = [(&#8220;a&#8221;, ta.int32), (&#8220;b&#8221;, ta.int32), (&#8220;c&#8221;, ta.float32), (&#8220;d&#8221;, ta.vector(2))]
d = &#8220;lbp.csv&#8221;
c = ta.CsvFile(d,s)
f = ta.Frame(c)
r = f.loopy_belief_propagation(&#8220;a&#8221;, &#8220;b&#8221;, &#8220;c&#8221;, &#8220;d&#8221;, &#8220;results&#8221;)
r[&#8216;frame&#8217;].inspect()
r[&#8216;report&#8217;]</p>
<p>The expected output is like this:</p>
<div class="code highlight-python"><div class="highlight"><pre><span class="p">{</span><span class="s">u&#39;value&#39;</span><span class="p">:</span> <span class="s">u&#39;======Graph Statistics======</span><span class="se">\n</span><span class="s">Number of vertices: 80000 (train: 56123, validate: 15930, test: 7947)</span><span class="se">\n</span><span class="s">Number of edges: 318400</span><span class="se">\n\n</span><span class="s">======LBP Configuration======</span><span class="se">\n</span><span class="s">maxSupersteps: 10</span><span class="se">\n</span><span class="s">convergenceThreshold: 0.000000</span><span class="se">\n</span><span class="s">anchorThreshold: 0.900000</span><span class="se">\n</span><span class="s">smoothing: 2.000000</span><span class="se">\n</span><span class="s">bidirectionalCheck: false</span><span class="se">\n</span><span class="s">ignoreVertexType: false</span><span class="se">\n</span><span class="s">maxProduct: false</span><span class="se">\n</span><span class="s">power: 0.000000</span><span class="se">\n\n</span><span class="s">======Learning Progress======</span><span class="se">\n</span><span class="s">superstep = 1</span><span class="se">\t</span><span class="s">avgTrainDelta = 0.594534</span><span class="se">\t</span><span class="s">avgValidateDelta = 0.542366</span><span class="se">\t</span><span class="s">avgTestDelta = 0.542801</span><span class="se">\n</span><span class="s">superstep = 2</span><span class="se">\t</span><span class="s">avgTrainDelta = 0.322596</span><span class="se">\t</span><span class="s">avgValidateDelta = 0.373647</span><span class="se">\t</span><span class="s">avgTestDelta = 0.371556</span><span class="se">\n</span><span class="s">superstep = 3</span><span class="se">\t</span><span class="s">avgTrainDelta = 0.180468</span><span class="se">\t</span><span class="s">avgValidateDelta = 0.194503</span><span class="se">\t</span><span class="s">avgTestDelta = 0.198478</span><span class="se">\n</span><span class="s">superstep = 4</span><span class="se">\t</span><span class="s">avgTrainDelta = 0.113280</span><span class="se">\t</span><span class="s">avgValidateDelta = 0.117436</span><span class="se">\t</span><span class="s">avgTestDelta = 0.122555</span><span class="se">\n</span><span class="s">superstep = 5</span><span class="se">\t</span><span class="s">avgTrainDelta = 0.076510</span><span class="se">\t</span><span class="s">avgValidateDelta = 0.074419</span><span class="se">\t</span><span class="s">avgTestDelta = 0.077451</span><span class="se">\n</span><span class="s">superstep = 6</span><span class="se">\t</span><span class="s">avgTrainDelta = 0.051452</span><span class="se">\t</span><span class="s">avgValidateDelta = 0.051683</span><span class="se">\t</span><span class="s">avgTestDelta = 0.052538</span><span class="se">\n</span><span class="s">superstep = 7</span><span class="se">\t</span><span class="s">avgTrainDelta = 0.038257</span><span class="se">\t</span><span class="s">avgValidateDelta = 0.033629</span><span class="se">\t</span><span class="s">avgTestDelta = 0.034017</span><span class="se">\n</span><span class="s">superstep = 8</span><span class="se">\t</span><span class="s">avgTrainDelta = 0.027924</span><span class="se">\t</span><span class="s">avgValidateDelta = 0.026722</span><span class="se">\t</span><span class="s">avgTestDelta = 0.025877</span><span class="se">\n</span><span class="s">superstep = 9</span><span class="se">\t</span><span class="s">avgTrainDelta = 0.022886</span><span class="se">\t</span><span class="s">avgValidateDelta = 0.019267</span><span class="se">\t</span><span class="s">avgTestDelta = 0.018190</span><span class="se">\n</span><span class="s">superstep = 10</span><span class="se">\t</span><span class="s">avgTrainDelta = 0.018271</span><span class="se">\t</span><span class="s">avgValidateDelta = 0.015924</span><span class="se">\t</span><span class="s">avgTestDelta = 0.015377&#39;</span><span class="p">}</span>
</pre></div>
</div>
</dd></dl>

</div>


          </div>
        </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container container-navbar-bottom">
      <div class="spc-navbar">
        
      </div>
    </div>
    <div class="container">
    <div class="footer">
    <div class="row-fluid">
    <ul class="inline pull-left">
      <li>
        &copy; Copyright 2015, Intel.
      </li>
      <li>
      Last updated on Sep 30, 2015.
      </li>
    </ul>
    </div>
    </div>
    </div>
  </body>
</html>